{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adb77b13",
      "metadata": {
        "id": "adb77b13"
      },
      "outputs": [],
      "source": [
        "import pandas as p\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd598f7a",
      "metadata": {
        "id": "fd598f7a"
      },
      "outputs": [],
      "source": [
        "x = np.load('/Users/coral/Desktop/Fold 1/images/fold1/images.npy')\n",
        "y = np.load('/Users/coral/Desktop/Fold 1/images/fold1/types.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25eb11b1",
      "metadata": {
        "id": "25eb11b1"
      },
      "outputs": [],
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e308ae7",
      "metadata": {
        "id": "7e308ae7",
        "outputId": "db7b9e42-1413-43ec-8a89-f8f9fd16fc94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2124, 256, 256, 3) (2124,)\n",
            "(532, 256, 256, 3) (532,)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape,y_train.shape)\n",
        "print(x_test.shape,y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2e16d00",
      "metadata": {
        "id": "a2e16d00",
        "outputId": "dd7e2489-c025-4a21-b7cd-cf3efe5644a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#encoding y_train\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "\n",
        "y_train = onehot_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee08e16b",
      "metadata": {
        "id": "ee08e16b",
        "outputId": "d81dc2c7-80d0-4bba-f43f-53b8c05973c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#encoding y_test\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(y_test)\n",
        "\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "\n",
        "y_test = onehot_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05bfa3eb",
      "metadata": {
        "id": "05bfa3eb"
      },
      "outputs": [],
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state= 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f847f218",
      "metadata": {
        "id": "f847f218",
        "outputId": "458a0480-4e76-4ee2-a2f9-03d364adc56d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1911, 256, 256, 3) (1911, 19)\n",
            "(213, 256, 256, 3) (213, 19)\n",
            "(532, 256, 256, 3) (532, 19)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape, y_train.shape)\n",
        "print(x_val.shape, y_val.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da4d725b",
      "metadata": {
        "id": "da4d725b"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7275c615",
      "metadata": {
        "scrolled": true,
        "id": "7275c615",
        "outputId": "4b8d4ac3-1299-463a-caa6-afb9ec436b91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "239/239 [==============================] - 5s 18ms/step - loss: 2.5258 - accuracy: 0.2711 - val_loss: 2.3829 - val_accuracy: 0.3286\n",
            "Epoch 2/35\n",
            "239/239 [==============================] - 4s 15ms/step - loss: 2.4681 - accuracy: 0.2841 - val_loss: 2.3850 - val_accuracy: 0.3286\n",
            "Epoch 3/35\n",
            "239/239 [==============================] - 4s 15ms/step - loss: 2.4317 - accuracy: 0.2983 - val_loss: 2.3151 - val_accuracy: 0.3286\n",
            "Epoch 4/35\n",
            "239/239 [==============================] - 4s 15ms/step - loss: 2.4071 - accuracy: 0.2878 - val_loss: 2.2836 - val_accuracy: 0.3286\n",
            "Epoch 5/35\n",
            "239/239 [==============================] - 4s 15ms/step - loss: 2.3648 - accuracy: 0.2904 - val_loss: 2.2630 - val_accuracy: 0.3286\n",
            "Epoch 6/35\n",
            "239/239 [==============================] - 4s 15ms/step - loss: 2.3401 - accuracy: 0.2821 - val_loss: 2.2302 - val_accuracy: 0.3380\n",
            "Epoch 7/35\n",
            "239/239 [==============================] - 4s 15ms/step - loss: 2.2910 - accuracy: 0.3051 - val_loss: 2.2326 - val_accuracy: 0.3380\n",
            "Epoch 8/35\n",
            "239/239 [==============================] - 4s 16ms/step - loss: 2.2687 - accuracy: 0.3182 - val_loss: 2.2561 - val_accuracy: 0.3286\n",
            "Epoch 9/35\n",
            "239/239 [==============================] - 4s 16ms/step - loss: 2.2373 - accuracy: 0.3365 - val_loss: 2.1746 - val_accuracy: 0.3521\n",
            "Epoch 10/35\n",
            "239/239 [==============================] - 4s 16ms/step - loss: 2.2052 - accuracy: 0.3281 - val_loss: 2.1309 - val_accuracy: 0.3568\n",
            "Epoch 11/35\n",
            "239/239 [==============================] - 4s 16ms/step - loss: 2.1996 - accuracy: 0.3564 - val_loss: 2.2255 - val_accuracy: 0.4601\n",
            "Epoch 12/35\n",
            "239/239 [==============================] - 4s 16ms/step - loss: 2.1690 - accuracy: 0.3679 - val_loss: 2.1595 - val_accuracy: 0.3192\n",
            "Epoch 13/35\n",
            "239/239 [==============================] - 4s 16ms/step - loss: 2.1403 - accuracy: 0.3878 - val_loss: 2.0438 - val_accuracy: 0.4648\n",
            "Epoch 14/35\n",
            "239/239 [==============================] - 4s 16ms/step - loss: 2.1164 - accuracy: 0.3904 - val_loss: 2.0121 - val_accuracy: 0.4648\n",
            "Epoch 15/35\n",
            "239/239 [==============================] - 4s 16ms/step - loss: 2.0823 - accuracy: 0.4103 - val_loss: 2.0237 - val_accuracy: 0.4836\n",
            "Epoch 16/35\n",
            "239/239 [==============================] - 4s 16ms/step - loss: 2.0671 - accuracy: 0.4207 - val_loss: 1.9620 - val_accuracy: 0.4601\n",
            "Epoch 17/35\n",
            "239/239 [==============================] - 4s 16ms/step - loss: 2.0412 - accuracy: 0.4239 - val_loss: 2.0630 - val_accuracy: 0.4178\n",
            "Epoch 18/35\n",
            "239/239 [==============================] - 4s 16ms/step - loss: 2.0229 - accuracy: 0.4354 - val_loss: 1.9326 - val_accuracy: 0.5023\n",
            "Epoch 19/35\n",
            "239/239 [==============================] - 4s 16ms/step - loss: 1.9845 - accuracy: 0.4390 - val_loss: 1.9545 - val_accuracy: 0.4366\n",
            "Epoch 20/35\n",
            "239/239 [==============================] - 4s 16ms/step - loss: 1.9496 - accuracy: 0.4479 - val_loss: 1.8872 - val_accuracy: 0.4836\n",
            "Epoch 21/35\n",
            "239/239 [==============================] - 4s 15ms/step - loss: 1.9625 - accuracy: 0.4589 - val_loss: 1.8861 - val_accuracy: 0.4977\n",
            "Epoch 22/35\n",
            "239/239 [==============================] - 4s 16ms/step - loss: 1.9336 - accuracy: 0.4621 - val_loss: 1.8460 - val_accuracy: 0.5164\n",
            "Epoch 23/35\n",
            "239/239 [==============================] - 4s 16ms/step - loss: 1.9091 - accuracy: 0.4736 - val_loss: 2.0006 - val_accuracy: 0.4319\n",
            "Epoch 24/35\n",
            "239/239 [==============================] - 4s 15ms/step - loss: 1.9059 - accuracy: 0.4762 - val_loss: 1.8647 - val_accuracy: 0.4836\n",
            "Epoch 25/35\n",
            "239/239 [==============================] - 4s 15ms/step - loss: 1.8832 - accuracy: 0.4720 - val_loss: 1.9111 - val_accuracy: 0.4789\n",
            "Epoch 26/35\n",
            "239/239 [==============================] - 4s 16ms/step - loss: 1.8721 - accuracy: 0.4725 - val_loss: 1.8382 - val_accuracy: 0.5023\n",
            "Epoch 27/35\n",
            "239/239 [==============================] - 4s 15ms/step - loss: 1.8559 - accuracy: 0.4772 - val_loss: 1.8636 - val_accuracy: 0.4742\n",
            "Epoch 28/35\n",
            "239/239 [==============================] - 4s 15ms/step - loss: 1.8332 - accuracy: 0.4835 - val_loss: 1.8541 - val_accuracy: 0.4836\n",
            "Epoch 29/35\n",
            "239/239 [==============================] - 4s 16ms/step - loss: 1.8404 - accuracy: 0.4877 - val_loss: 1.8138 - val_accuracy: 0.4883\n",
            "Epoch 30/35\n",
            "239/239 [==============================] - 4s 16ms/step - loss: 1.8155 - accuracy: 0.4846 - val_loss: 1.8228 - val_accuracy: 0.4742\n",
            "Epoch 31/35\n",
            "239/239 [==============================] - 4s 16ms/step - loss: 1.7796 - accuracy: 0.4908 - val_loss: 2.0549 - val_accuracy: 0.4319\n",
            "Epoch 32/35\n",
            "239/239 [==============================] - 4s 15ms/step - loss: 1.7916 - accuracy: 0.4956 - val_loss: 1.7732 - val_accuracy: 0.4930\n",
            "Epoch 33/35\n",
            "239/239 [==============================] - 4s 15ms/step - loss: 1.7876 - accuracy: 0.4935 - val_loss: 1.8050 - val_accuracy: 0.5070\n",
            "Epoch 34/35\n",
            "239/239 [==============================] - 4s 15ms/step - loss: 1.7838 - accuracy: 0.4903 - val_loss: 1.8071 - val_accuracy: 0.4742\n",
            "Epoch 35/35\n",
            "239/239 [==============================] - 4s 16ms/step - loss: 1.7445 - accuracy: 0.5050 - val_loss: 1.8348 - val_accuracy: 0.5023\n",
            "17/17 [==============================] - 1s 29ms/step\n",
            "Test Accuracy: 0.4756\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the model\n",
        "model_cnn = Sequential()\n",
        "model_cnn.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
        "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_cnn.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_cnn.add(Flatten())\n",
        "model_cnn.add(Dense(64, activation='relu'))\n",
        "model_cnn.add(Dropout(0.3))\n",
        "model_cnn.add(Dense(19, activation='softmax'))\n",
        "\n",
        "\n",
        "model_cnn.compile(optimizer=SGD(learning_rate=0.001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Data conversion\n",
        "x_train = x_train / 255.0\n",
        "x_val = x_val / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Train the model\n",
        "history = model_cnn.fit(x_train, y_train,\n",
        "                        batch_size=8,\n",
        "                        epochs=35,\n",
        "                        validation_data=(x_val, y_val),\n",
        "                        verbose=1)\n",
        "\n",
        "# Accuracy\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Evaluation\n",
        "test_predictions = model_cnn.predict(x_test)\n",
        "test_predictions = np.argmax(test_predictions, axis=1)\n",
        "test_labels = np.argmax(y_test, axis=1)\n",
        "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "\n",
        "print('Train Accuracy: {:.4f}'.format(train_accuracy[-1]))\n",
        "print('Validation Accuracy: {:.4f}'.format(val_accuracy[-1]))\n",
        "print('Test Accuracy: {:.4f}'.format(test_accuracy))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f54f8cdf",
      "metadata": {
        "id": "f54f8cdf"
      },
      "source": [
        "## U-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b6496bf",
      "metadata": {
        "scrolled": true,
        "id": "8b6496bf",
        "outputId": "db063b11-80e5-42a2-f54f-9f49d5488fcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "239/239 [==============================] - 12s 37ms/step - loss: 2.4242 - accuracy: 0.2878 - val_loss: 2.1848 - val_accuracy: 0.3615\n",
            "Epoch 2/35\n",
            "239/239 [==============================] - 8s 32ms/step - loss: 2.2612 - accuracy: 0.3082 - val_loss: 2.3352 - val_accuracy: 0.3521\n",
            "Epoch 3/35\n",
            "239/239 [==============================] - 8s 32ms/step - loss: 2.2286 - accuracy: 0.3119 - val_loss: 2.1375 - val_accuracy: 0.3427\n",
            "Epoch 4/35\n",
            "239/239 [==============================] - 8s 32ms/step - loss: 2.1429 - accuracy: 0.3234 - val_loss: 2.1787 - val_accuracy: 0.3615\n",
            "Epoch 5/35\n",
            "239/239 [==============================] - 8s 32ms/step - loss: 2.0332 - accuracy: 0.3459 - val_loss: 2.1531 - val_accuracy: 0.3474\n",
            "Epoch 6/35\n",
            "239/239 [==============================] - 8s 32ms/step - loss: 1.8601 - accuracy: 0.3993 - val_loss: 2.2444 - val_accuracy: 0.3427\n",
            "Epoch 7/35\n",
            "239/239 [==============================] - 8s 32ms/step - loss: 1.6404 - accuracy: 0.4553 - val_loss: 2.2548 - val_accuracy: 0.4178\n",
            "Epoch 8/35\n",
            "239/239 [==============================] - 8s 32ms/step - loss: 1.3923 - accuracy: 0.5437 - val_loss: 2.3647 - val_accuracy: 0.3991\n",
            "Epoch 9/35\n",
            "239/239 [==============================] - 8s 32ms/step - loss: 1.1485 - accuracy: 0.6117 - val_loss: 2.7678 - val_accuracy: 0.3756\n",
            "Epoch 10/35\n",
            "239/239 [==============================] - 8s 32ms/step - loss: 0.9009 - accuracy: 0.6949 - val_loss: 3.0244 - val_accuracy: 0.3944\n",
            "Epoch 11/35\n",
            "239/239 [==============================] - 8s 32ms/step - loss: 0.8020 - accuracy: 0.7300 - val_loss: 3.5362 - val_accuracy: 0.3709\n",
            "Epoch 12/35\n",
            "239/239 [==============================] - 8s 32ms/step - loss: 0.7524 - accuracy: 0.7582 - val_loss: 3.5491 - val_accuracy: 0.3991\n",
            "Epoch 13/35\n",
            "239/239 [==============================] - 8s 32ms/step - loss: 0.7043 - accuracy: 0.7729 - val_loss: 4.0158 - val_accuracy: 0.4272\n",
            "Epoch 14/35\n",
            "239/239 [==============================] - 8s 33ms/step - loss: 0.5827 - accuracy: 0.7970 - val_loss: 4.7336 - val_accuracy: 0.3944\n",
            "Epoch 15/35\n",
            "239/239 [==============================] - 8s 33ms/step - loss: 0.6411 - accuracy: 0.7886 - val_loss: 4.6527 - val_accuracy: 0.3756\n",
            "Epoch 16/35\n",
            "239/239 [==============================] - 8s 33ms/step - loss: 0.6061 - accuracy: 0.8069 - val_loss: 4.8511 - val_accuracy: 0.4085\n",
            "Epoch 17/35\n",
            "239/239 [==============================] - 8s 33ms/step - loss: 0.4711 - accuracy: 0.8577 - val_loss: 3.8331 - val_accuracy: 0.4178\n",
            "Epoch 18/35\n",
            "239/239 [==============================] - 8s 33ms/step - loss: 0.4758 - accuracy: 0.8435 - val_loss: 4.8224 - val_accuracy: 0.3803\n",
            "Epoch 19/35\n",
            "239/239 [==============================] - 8s 33ms/step - loss: 0.4824 - accuracy: 0.8388 - val_loss: 5.6464 - val_accuracy: 0.4131\n",
            "Epoch 20/35\n",
            "239/239 [==============================] - 8s 32ms/step - loss: 0.4447 - accuracy: 0.8571 - val_loss: 4.8916 - val_accuracy: 0.3662\n",
            "Epoch 21/35\n",
            "239/239 [==============================] - 8s 33ms/step - loss: 0.3787 - accuracy: 0.8707 - val_loss: 5.2170 - val_accuracy: 0.3756\n",
            "Epoch 22/35\n",
            "239/239 [==============================] - 8s 33ms/step - loss: 0.3924 - accuracy: 0.8776 - val_loss: 5.4136 - val_accuracy: 0.3662\n",
            "Epoch 23/35\n",
            "239/239 [==============================] - 8s 33ms/step - loss: 0.3540 - accuracy: 0.8807 - val_loss: 5.2343 - val_accuracy: 0.3756\n",
            "Epoch 24/35\n",
            "239/239 [==============================] - 8s 33ms/step - loss: 0.3423 - accuracy: 0.8980 - val_loss: 5.3275 - val_accuracy: 0.3615\n",
            "Epoch 25/35\n",
            "239/239 [==============================] - 8s 33ms/step - loss: 0.3402 - accuracy: 0.8864 - val_loss: 6.0836 - val_accuracy: 0.3756\n",
            "Epoch 26/35\n",
            "239/239 [==============================] - 8s 33ms/step - loss: 0.3207 - accuracy: 0.8896 - val_loss: 6.3209 - val_accuracy: 0.3991\n",
            "Epoch 27/35\n",
            "239/239 [==============================] - 8s 34ms/step - loss: 0.3125 - accuracy: 0.8922 - val_loss: 7.6025 - val_accuracy: 0.3897\n",
            "Epoch 28/35\n",
            "239/239 [==============================] - 8s 34ms/step - loss: 0.2920 - accuracy: 0.9048 - val_loss: 5.4990 - val_accuracy: 0.3474\n",
            "Epoch 29/35\n",
            "239/239 [==============================] - 8s 34ms/step - loss: 0.2810 - accuracy: 0.8980 - val_loss: 6.6579 - val_accuracy: 0.3709\n",
            "Epoch 30/35\n",
            "239/239 [==============================] - 8s 33ms/step - loss: 0.3262 - accuracy: 0.8938 - val_loss: 5.4993 - val_accuracy: 0.3474\n",
            "Epoch 31/35\n",
            "239/239 [==============================] - 8s 33ms/step - loss: 0.2544 - accuracy: 0.9089 - val_loss: 5.1937 - val_accuracy: 0.3568\n",
            "Epoch 32/35\n",
            "239/239 [==============================] - 8s 33ms/step - loss: 0.2393 - accuracy: 0.9158 - val_loss: 7.0961 - val_accuracy: 0.3756\n",
            "Epoch 33/35\n",
            "239/239 [==============================] - 8s 34ms/step - loss: 0.2713 - accuracy: 0.9053 - val_loss: 6.0896 - val_accuracy: 0.3756\n",
            "Epoch 34/35\n",
            "239/239 [==============================] - 8s 33ms/step - loss: 0.2758 - accuracy: 0.9089 - val_loss: 5.9904 - val_accuracy: 0.3897\n",
            "Epoch 35/35\n",
            "239/239 [==============================] - 8s 33ms/step - loss: 0.2351 - accuracy: 0.9178 - val_loss: 7.8412 - val_accuracy: 0.3991\n",
            "17/17 [==============================] - 2s 64ms/step\n",
            "Test Accuracy: 0.3496\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the model\n",
        "model_fcn = Sequential()\n",
        "model_fcn.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
        "model_fcn.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model_fcn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_fcn.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model_fcn.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model_fcn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_fcn.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model_fcn.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model_fcn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_fcn.add(Flatten())\n",
        "model_fcn.add(Dense(64, activation='relu'))\n",
        "model_fcn.add(Dropout(0.3))\n",
        "model_fcn.add(Dense(19, activation='softmax'))\n",
        "\n",
        "\n",
        "model_fcn.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Data conversion\n",
        "x_train = x_train / 255.0\n",
        "x_val = x_val / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Train the model\n",
        "history = model_fcn.fit(x_train, y_train,\n",
        "                        batch_size=8,\n",
        "                        epochs=35,\n",
        "                        validation_data=(x_val, y_val),\n",
        "                        verbose=1)\n",
        "\n",
        "# Accuracy\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "test_predictions = model_fcn.predict(x_test)\n",
        "test_predictions = np.argmax(test_predictions, axis=1)\n",
        "test_labels = np.argmax(y_test, axis=1)\n",
        "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "\n",
        "print('Train Accuracy: {:.4f}'.format(train_accuracy[-1]))\n",
        "print('Validation Accuracy: {:.4f}'.format(val_accuracy[-1]))\n",
        "print('Test Accuracy: {:.4f}'.format(test_accuracy))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11920aa5",
      "metadata": {
        "id": "11920aa5"
      },
      "source": [
        "## Restnet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b54c6720",
      "metadata": {
        "scrolled": true,
        "id": "b54c6720",
        "outputId": "30f7b247-4987-449a-b4ab-24172408d70c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "239/239 [==============================] - 29s 96ms/step - loss: 2.0977 - accuracy: 0.4014 - val_loss: 23.3741 - val_accuracy: 0.1596\n",
            "Epoch 2/35\n",
            "239/239 [==============================] - 21s 87ms/step - loss: 1.5782 - accuracy: 0.5175 - val_loss: 7.8868 - val_accuracy: 0.1408\n",
            "Epoch 3/35\n",
            "239/239 [==============================] - 21s 87ms/step - loss: 1.3179 - accuracy: 0.5945 - val_loss: 3.8912 - val_accuracy: 0.2958\n",
            "Epoch 4/35\n",
            "239/239 [==============================] - 21s 87ms/step - loss: 1.0271 - accuracy: 0.6745 - val_loss: 2.2283 - val_accuracy: 0.4178\n",
            "Epoch 5/35\n",
            "239/239 [==============================] - 21s 88ms/step - loss: 0.7370 - accuracy: 0.7713 - val_loss: 1.6624 - val_accuracy: 0.5446\n",
            "Epoch 6/35\n",
            "239/239 [==============================] - 21s 89ms/step - loss: 0.5525 - accuracy: 0.8221 - val_loss: 1.5360 - val_accuracy: 0.5915\n",
            "Epoch 7/35\n",
            "239/239 [==============================] - 21s 89ms/step - loss: 0.4013 - accuracy: 0.8796 - val_loss: 1.4595 - val_accuracy: 0.6103\n",
            "Epoch 8/35\n",
            "239/239 [==============================] - 21s 89ms/step - loss: 0.3294 - accuracy: 0.8922 - val_loss: 1.4343 - val_accuracy: 0.6432\n",
            "Epoch 9/35\n",
            "239/239 [==============================] - 22s 90ms/step - loss: 0.2588 - accuracy: 0.9189 - val_loss: 1.4452 - val_accuracy: 0.6432\n",
            "Epoch 10/35\n",
            "239/239 [==============================] - 22s 90ms/step - loss: 0.2201 - accuracy: 0.9320 - val_loss: 1.5795 - val_accuracy: 0.6338\n",
            "Epoch 11/35\n",
            "239/239 [==============================] - 22s 90ms/step - loss: 0.1732 - accuracy: 0.9424 - val_loss: 1.4316 - val_accuracy: 0.6526\n",
            "Epoch 12/35\n",
            "239/239 [==============================] - 22s 90ms/step - loss: 0.1653 - accuracy: 0.9534 - val_loss: 1.3383 - val_accuracy: 0.6995\n",
            "Epoch 13/35\n",
            "239/239 [==============================] - 22s 90ms/step - loss: 0.1318 - accuracy: 0.9540 - val_loss: 1.6358 - val_accuracy: 0.6761\n",
            "Epoch 14/35\n",
            "239/239 [==============================] - 22s 90ms/step - loss: 0.1109 - accuracy: 0.9628 - val_loss: 1.3133 - val_accuracy: 0.6995\n",
            "Epoch 15/35\n",
            "239/239 [==============================] - 22s 91ms/step - loss: 0.1070 - accuracy: 0.9644 - val_loss: 1.7362 - val_accuracy: 0.6667\n",
            "Epoch 16/35\n",
            "239/239 [==============================] - 22s 91ms/step - loss: 0.1083 - accuracy: 0.9639 - val_loss: 1.6190 - val_accuracy: 0.6901\n",
            "Epoch 17/35\n",
            "239/239 [==============================] - 22s 91ms/step - loss: 0.0964 - accuracy: 0.9676 - val_loss: 1.8930 - val_accuracy: 0.6432\n",
            "Epoch 18/35\n",
            "239/239 [==============================] - 22s 91ms/step - loss: 0.0800 - accuracy: 0.9801 - val_loss: 1.5182 - val_accuracy: 0.7042\n",
            "Epoch 19/35\n",
            "239/239 [==============================] - 22s 91ms/step - loss: 0.0768 - accuracy: 0.9770 - val_loss: 1.3915 - val_accuracy: 0.7089\n",
            "Epoch 20/35\n",
            "239/239 [==============================] - 22s 92ms/step - loss: 0.0779 - accuracy: 0.9765 - val_loss: 1.5042 - val_accuracy: 0.6667\n",
            "Epoch 21/35\n",
            "239/239 [==============================] - 22s 92ms/step - loss: 0.0751 - accuracy: 0.9765 - val_loss: 1.5482 - val_accuracy: 0.6854\n",
            "Epoch 22/35\n",
            "239/239 [==============================] - 22s 92ms/step - loss: 0.0689 - accuracy: 0.9791 - val_loss: 1.6519 - val_accuracy: 0.6385\n",
            "Epoch 23/35\n",
            "239/239 [==============================] - 22s 92ms/step - loss: 0.0633 - accuracy: 0.9780 - val_loss: 1.5161 - val_accuracy: 0.6995\n",
            "Epoch 24/35\n",
            "239/239 [==============================] - 22s 92ms/step - loss: 0.0491 - accuracy: 0.9848 - val_loss: 1.5068 - val_accuracy: 0.6854\n",
            "Epoch 25/35\n",
            "239/239 [==============================] - 22s 91ms/step - loss: 0.0515 - accuracy: 0.9822 - val_loss: 1.7639 - val_accuracy: 0.6667\n",
            "Epoch 26/35\n",
            "239/239 [==============================] - 22s 91ms/step - loss: 0.0503 - accuracy: 0.9853 - val_loss: 1.4637 - val_accuracy: 0.6901\n",
            "Epoch 27/35\n",
            "239/239 [==============================] - 22s 92ms/step - loss: 0.0459 - accuracy: 0.9843 - val_loss: 1.5006 - val_accuracy: 0.6808\n",
            "Epoch 28/35\n",
            "239/239 [==============================] - 22s 92ms/step - loss: 0.0413 - accuracy: 0.9864 - val_loss: 1.7758 - val_accuracy: 0.6761\n",
            "Epoch 29/35\n",
            "239/239 [==============================] - 22s 92ms/step - loss: 0.0499 - accuracy: 0.9848 - val_loss: 1.6101 - val_accuracy: 0.6526\n",
            "Epoch 30/35\n",
            "239/239 [==============================] - 22s 91ms/step - loss: 0.0435 - accuracy: 0.9890 - val_loss: 1.7223 - val_accuracy: 0.6526\n",
            "Epoch 31/35\n",
            "239/239 [==============================] - 22s 91ms/step - loss: 0.0455 - accuracy: 0.9843 - val_loss: 1.5957 - val_accuracy: 0.6479\n",
            "Epoch 32/35\n",
            "239/239 [==============================] - 22s 92ms/step - loss: 0.0381 - accuracy: 0.9890 - val_loss: 1.7204 - val_accuracy: 0.6995\n",
            "Epoch 33/35\n",
            "239/239 [==============================] - 22s 91ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 1.5300 - val_accuracy: 0.7042\n",
            "Epoch 34/35\n",
            "239/239 [==============================] - 22s 91ms/step - loss: 0.0404 - accuracy: 0.9864 - val_loss: 1.5562 - val_accuracy: 0.6854\n",
            "Epoch 35/35\n",
            "239/239 [==============================] - 22s 91ms/step - loss: 0.0334 - accuracy: 0.9859 - val_loss: 1.6856 - val_accuracy: 0.6808\n",
            "17/17 [==============================] - 3s 104ms/step\n",
            "Test Accuracy: 0.6654\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.applications import ResNet50\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Dropout\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialization\n",
        "base_model_resnet = ResNet50(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(256, 256, 3)\n",
        ")\n",
        "\n",
        "\n",
        "model_resnet = Sequential()\n",
        "model_resnet.add(base_model_resnet)\n",
        "model_resnet.add(Flatten())\n",
        "model_resnet.add(Dense(64, activation='relu'))\n",
        "model_resnet.add(Dropout(0.3))\n",
        "model_resnet.add(Dense(19, activation='softmax'))\n",
        "\n",
        "# Model\n",
        "model_resnet.compile(\n",
        "    optimizer=SGD(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Data conversion\n",
        "x_train = x_train / 255.0\n",
        "x_val = x_val / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Train the model\n",
        "history = model_resnet.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=8,\n",
        "    epochs=35,\n",
        "    validation_data=(x_val, y_val),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Accuracy\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Evaluation\n",
        "test_predictions = model_resnet.predict(x_test)\n",
        "test_predictions = np.argmax(test_predictions, axis=1)\n",
        "test_labels = np.argmax(y_test, axis=1)\n",
        "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "\n",
        "print('Train Accuracy: {:.4f}'.format(train_accuracy[-1]))\n",
        "print('Validation Accuracy: {:.4f}'.format(val_accuracy[-1]))\n",
        "print('Test Accuracy: {:.4f}'.format(test_accuracy))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22fb3aba",
      "metadata": {
        "id": "22fb3aba"
      },
      "source": [
        "## VGG19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b18d4532",
      "metadata": {
        "scrolled": true,
        "id": "b18d4532",
        "outputId": "ccb3ba6b-cec7-42e7-f3d2-892a9e53a427"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\Anaconda\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "238/238 [==============================] - 23s 86ms/step - loss: 2.9470 - accuracy: 0.2780 - val_loss: 3.0237 - val_accuracy: 0.0939\n",
            "Epoch 2/40\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 2.9118 - accuracy: 0.3127 - val_loss: 3.0011 - val_accuracy: 0.1033\n",
            "Epoch 3/40\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 2.8892 - accuracy: 0.3142 - val_loss: 2.9793 - val_accuracy: 0.1268\n",
            "Epoch 4/40\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 2.8679 - accuracy: 0.3121 - val_loss: 2.9581 - val_accuracy: 0.1315\n",
            "Epoch 5/40\n",
            "238/238 [==============================] - 18s 75ms/step - loss: 2.8464 - accuracy: 0.3142 - val_loss: 2.9376 - val_accuracy: 0.1408\n",
            "Epoch 6/40\n",
            "238/238 [==============================] - 19s 78ms/step - loss: 2.8257 - accuracy: 0.3142 - val_loss: 2.9175 - val_accuracy: 0.1362\n",
            "Epoch 7/40\n",
            "238/238 [==============================] - 18s 77ms/step - loss: 2.8065 - accuracy: 0.3127 - val_loss: 2.8980 - val_accuracy: 0.1408\n",
            "Epoch 8/40\n",
            "238/238 [==============================] - 19s 78ms/step - loss: 2.7873 - accuracy: 0.3132 - val_loss: 2.8792 - val_accuracy: 0.1455\n",
            "Epoch 9/40\n",
            "238/238 [==============================] - 19s 80ms/step - loss: 2.7689 - accuracy: 0.3132 - val_loss: 2.8612 - val_accuracy: 0.1596\n",
            "Epoch 10/40\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 2.7516 - accuracy: 0.3116 - val_loss: 2.8438 - val_accuracy: 0.1643\n",
            "Epoch 11/40\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 2.7337 - accuracy: 0.3132 - val_loss: 2.8267 - val_accuracy: 0.1643\n",
            "Epoch 12/40\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 2.7174 - accuracy: 0.3132 - val_loss: 2.8105 - val_accuracy: 0.1596\n",
            "Epoch 13/40\n",
            "238/238 [==============================] - 19s 80ms/step - loss: 2.7003 - accuracy: 0.3142 - val_loss: 2.7947 - val_accuracy: 0.1643\n",
            "Epoch 14/40\n",
            "238/238 [==============================] - 18s 77ms/step - loss: 2.6856 - accuracy: 0.3142 - val_loss: 2.7796 - val_accuracy: 0.1643\n",
            "Epoch 15/40\n",
            "238/238 [==============================] - 19s 78ms/step - loss: 2.6719 - accuracy: 0.3127 - val_loss: 2.7653 - val_accuracy: 0.1643\n",
            "Epoch 16/40\n",
            "238/238 [==============================] - 19s 80ms/step - loss: 2.6572 - accuracy: 0.3137 - val_loss: 2.7513 - val_accuracy: 0.1643\n",
            "Epoch 17/40\n",
            "238/238 [==============================] - 19s 80ms/step - loss: 2.6437 - accuracy: 0.3137 - val_loss: 2.7381 - val_accuracy: 0.1643\n",
            "Epoch 18/40\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 2.6317 - accuracy: 0.3132 - val_loss: 2.7254 - val_accuracy: 0.1643\n",
            "Epoch 19/40\n",
            "238/238 [==============================] - 19s 80ms/step - loss: 2.6189 - accuracy: 0.3137 - val_loss: 2.7133 - val_accuracy: 0.1596\n",
            "Epoch 20/40\n",
            "238/238 [==============================] - 18s 77ms/step - loss: 2.6078 - accuracy: 0.3132 - val_loss: 2.7020 - val_accuracy: 0.1596\n",
            "Epoch 21/40\n",
            "238/238 [==============================] - 19s 78ms/step - loss: 2.5967 - accuracy: 0.3132 - val_loss: 2.6909 - val_accuracy: 0.1596\n",
            "Epoch 22/40\n",
            "238/238 [==============================] - 19s 79ms/step - loss: 2.5853 - accuracy: 0.3137 - val_loss: 2.6806 - val_accuracy: 0.1549\n",
            "Epoch 23/40\n",
            "238/238 [==============================] - 19s 79ms/step - loss: 2.5760 - accuracy: 0.3132 - val_loss: 2.6706 - val_accuracy: 0.1549\n",
            "Epoch 24/40\n",
            "238/238 [==============================] - 19s 78ms/step - loss: 2.5658 - accuracy: 0.3142 - val_loss: 2.6612 - val_accuracy: 0.1549\n",
            "Epoch 25/40\n",
            "238/238 [==============================] - 19s 78ms/step - loss: 2.5579 - accuracy: 0.3127 - val_loss: 2.6523 - val_accuracy: 0.1549\n",
            "Epoch 26/40\n",
            "238/238 [==============================] - 19s 78ms/step - loss: 2.5483 - accuracy: 0.3137 - val_loss: 2.6440 - val_accuracy: 0.1549\n",
            "Epoch 27/40\n",
            "238/238 [==============================] - 19s 79ms/step - loss: 2.5396 - accuracy: 0.3142 - val_loss: 2.6358 - val_accuracy: 0.1549\n",
            "Epoch 28/40\n",
            "238/238 [==============================] - 19s 80ms/step - loss: 2.5334 - accuracy: 0.3132 - val_loss: 2.6284 - val_accuracy: 0.1502\n",
            "Epoch 29/40\n",
            "238/238 [==============================] - 19s 78ms/step - loss: 2.5247 - accuracy: 0.3142 - val_loss: 2.6212 - val_accuracy: 0.1455\n",
            "Epoch 30/40\n",
            "238/238 [==============================] - 18s 77ms/step - loss: 2.5195 - accuracy: 0.3137 - val_loss: 2.6102 - val_accuracy: 0.1549\n",
            "Epoch 31/40\n",
            "238/238 [==============================] - 19s 79ms/step - loss: 2.5143 - accuracy: 0.3127 - val_loss: 2.6040 - val_accuracy: 0.1596\n",
            "Epoch 32/40\n",
            "238/238 [==============================] - 19s 79ms/step - loss: 2.5075 - accuracy: 0.3137 - val_loss: 2.5983 - val_accuracy: 0.1643\n",
            "Epoch 33/40\n",
            "238/238 [==============================] - 19s 78ms/step - loss: 2.5017 - accuracy: 0.3132 - val_loss: 2.5927 - val_accuracy: 0.1690\n",
            "Epoch 34/40\n",
            "238/238 [==============================] - 19s 79ms/step - loss: 2.4942 - accuracy: 0.3142 - val_loss: 2.5876 - val_accuracy: 0.1690\n",
            "Epoch 35/40\n",
            "238/238 [==============================] - 19s 80ms/step - loss: 2.4911 - accuracy: 0.3132 - val_loss: 2.5827 - val_accuracy: 0.1690\n",
            "Epoch 36/40\n",
            "238/238 [==============================] - 19s 79ms/step - loss: 2.4865 - accuracy: 0.3137 - val_loss: 2.5781 - val_accuracy: 0.1643\n",
            "Epoch 37/40\n",
            "238/238 [==============================] - 18s 77ms/step - loss: 2.4804 - accuracy: 0.3137 - val_loss: 2.5738 - val_accuracy: 0.1643\n",
            "Epoch 38/40\n",
            "238/238 [==============================] - 19s 79ms/step - loss: 2.4763 - accuracy: 0.3137 - val_loss: 2.5700 - val_accuracy: 0.1643\n",
            "Epoch 39/40\n",
            "238/238 [==============================] - 19s 78ms/step - loss: 2.4731 - accuracy: 0.3132 - val_loss: 2.5663 - val_accuracy: 0.1690\n",
            "Epoch 40/40\n",
            "238/238 [==============================] - 19s 80ms/step - loss: 2.4702 - accuracy: 0.3121 - val_loss: 2.5629 - val_accuracy: 0.1690\n",
            "17/17 [==============================] - 4s 240ms/step - loss: 2.5999 - accuracy: 0.1485\n",
            "Test Accuracy: 0.1485\n"
          ]
        }
      ],
      "source": [
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.models import Model\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "base_model = VGG19(include_top=False, input_shape=(256, 256, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "output = Dense(19, activation='softmax')(x)\n",
        "\n",
        "# Model\n",
        "model = Model(inputs=base_model.inputs, outputs=output)\n",
        "opt = SGD(lr=0.0001, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(featurewise_center=True, rotation_range=2, zoom_range=.2)\n",
        "datagen.mean = [123.68, 116.779, 103.939]\n",
        "\n",
        "# Data Conversion\n",
        "x_train = x_train / 255.0\n",
        "x_val = x_val / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "\n",
        "batch_size = 8\n",
        "steps_per_epoch = len(x_train) // batch_size\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    epochs=40,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)\n",
        "\n",
        "# Accuracy\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "print('Train Accuracy: {:.4f}'.format(train_accuracy[-1]))\n",
        "print('Validation Accuracy: {:.4f}'.format(val_accuracy[-1]))\n",
        "print('Test Accuracy: {:.4f}'.format(test_accuracy))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}